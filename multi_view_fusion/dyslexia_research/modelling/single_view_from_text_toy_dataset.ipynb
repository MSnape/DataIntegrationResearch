{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3d2c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-21 18:43:19.386833: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-21 18:43:20.039864: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/config/anaconda3/envs/imperial_3_12_linux/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from CSV...\n",
      "Total samples: 95\n",
      "Loading BERT tokenizer and tokenizing all text...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/config/anaconda3/envs/imperial_3_12_linux/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All text tokenized. Input IDs shape: (95, 128), Attention Masks shape: (95, 128)\n",
      "Training samples: 66\n",
      "Validation samples: 14\n",
      "TensorFlow Datasets created from preprocessed NumPy arrays for text.\n",
      "Building single-view text model architecture...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT model wrapped in custom layer and layers frozen.\n",
      "Compiling text model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ attention_mask      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_ids           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bert_feature_extra… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ attention_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BertEmbeddingLaye…</span> │                   │            │ input_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">590,592</span> │ bert_feature_ext… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">769</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ attention_mask      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_ids           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bert_feature_extra… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ attention_mask[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mBertEmbeddingLaye…\u001b[0m │                   │            │ input_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)       │    \u001b[38;5;34m590,592\u001b[0m │ bert_feature_ext… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │        \u001b[38;5;34m769\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">591,361</span> (2.26 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m591,361\u001b[0m (2.26 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">591,361</span> (2.26 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m591,361\u001b[0m (2.26 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training text model...\n",
      "Epoch 1/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 629ms/step - accuracy: 0.5581 - loss: 0.6945 - val_accuracy: 0.7143 - val_loss: 0.6279\n",
      "Epoch 2/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 407ms/step - accuracy: 0.8655 - loss: 0.5882 - val_accuracy: 0.8571 - val_loss: 0.5718\n",
      "Epoch 3/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 406ms/step - accuracy: 0.9339 - loss: 0.5143 - val_accuracy: 0.7143 - val_loss: 0.5328\n",
      "Epoch 4/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 409ms/step - accuracy: 0.9339 - loss: 0.4558 - val_accuracy: 0.7143 - val_loss: 0.4971\n",
      "Epoch 5/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 406ms/step - accuracy: 0.9451 - loss: 0.4004 - val_accuracy: 0.8571 - val_loss: 0.4645\n",
      "Epoch 6/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 411ms/step - accuracy: 0.9837 - loss: 0.3526 - val_accuracy: 0.7857 - val_loss: 0.4407\n",
      "Epoch 7/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 407ms/step - accuracy: 0.9725 - loss: 0.3161 - val_accuracy: 0.7857 - val_loss: 0.4216\n",
      "Epoch 8/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 407ms/step - accuracy: 0.9837 - loss: 0.2859 - val_accuracy: 0.7857 - val_loss: 0.4036\n",
      "Epoch 9/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 408ms/step - accuracy: 0.9837 - loss: 0.2591 - val_accuracy: 0.8571 - val_loss: 0.3877\n",
      "Epoch 10/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 408ms/step - accuracy: 0.9837 - loss: 0.2356 - val_accuracy: 0.8571 - val_loss: 0.3748\n",
      "Epoch 11/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 408ms/step - accuracy: 0.9837 - loss: 0.2152 - val_accuracy: 0.8571 - val_loss: 0.3654\n",
      "Epoch 12/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 406ms/step - accuracy: 0.9837 - loss: 0.1975 - val_accuracy: 0.8571 - val_loss: 0.3581\n",
      "Epoch 13/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 409ms/step - accuracy: 0.9837 - loss: 0.1822 - val_accuracy: 0.8571 - val_loss: 0.3517\n",
      "Epoch 14/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 409ms/step - accuracy: 0.9837 - loss: 0.1689 - val_accuracy: 0.9286 - val_loss: 0.3454\n",
      "Epoch 15/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 404ms/step - accuracy: 0.9837 - loss: 0.1570 - val_accuracy: 0.9286 - val_loss: 0.3389\n",
      "Epoch 16/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 405ms/step - accuracy: 0.9837 - loss: 0.1462 - val_accuracy: 0.9286 - val_loss: 0.3331\n",
      "Epoch 17/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 406ms/step - accuracy: 0.9837 - loss: 0.1365 - val_accuracy: 0.9286 - val_loss: 0.3280\n",
      "Epoch 18/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 410ms/step - accuracy: 1.0000 - loss: 0.1277 - val_accuracy: 0.9286 - val_loss: 0.3236\n",
      "Epoch 19/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 410ms/step - accuracy: 1.0000 - loss: 0.1198 - val_accuracy: 0.9286 - val_loss: 0.3195\n",
      "Epoch 20/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 406ms/step - accuracy: 1.0000 - loss: 0.1126 - val_accuracy: 0.9286 - val_loss: 0.3157\n",
      "Epoch 21/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 403ms/step - accuracy: 1.0000 - loss: 0.1059 - val_accuracy: 0.9286 - val_loss: 0.3122\n",
      "Epoch 22/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 408ms/step - accuracy: 1.0000 - loss: 0.0998 - val_accuracy: 0.9286 - val_loss: 0.3088\n",
      "Epoch 23/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 407ms/step - accuracy: 1.0000 - loss: 0.0942 - val_accuracy: 0.9286 - val_loss: 0.3058\n",
      "Epoch 24/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 406ms/step - accuracy: 1.0000 - loss: 0.0891 - val_accuracy: 0.9286 - val_loss: 0.3031\n",
      "Epoch 25/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 409ms/step - accuracy: 1.0000 - loss: 0.0843 - val_accuracy: 0.9286 - val_loss: 0.3005\n",
      "Epoch 26/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 410ms/step - accuracy: 1.0000 - loss: 0.0799 - val_accuracy: 0.9286 - val_loss: 0.2979\n",
      "Epoch 27/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 412ms/step - accuracy: 1.0000 - loss: 0.0758 - val_accuracy: 0.9286 - val_loss: 0.2955\n",
      "Epoch 28/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 411ms/step - accuracy: 1.0000 - loss: 0.0720 - val_accuracy: 0.9286 - val_loss: 0.2932\n",
      "Epoch 29/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 474ms/step - accuracy: 1.0000 - loss: 0.0684 - val_accuracy: 0.9286 - val_loss: 0.2909\n",
      "Epoch 30/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 407ms/step - accuracy: 1.0000 - loss: 0.0651 - val_accuracy: 0.9286 - val_loss: 0.2887\n",
      "Epoch 31/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 408ms/step - accuracy: 1.0000 - loss: 0.0620 - val_accuracy: 0.9286 - val_loss: 0.2868\n",
      "Epoch 32/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 405ms/step - accuracy: 1.0000 - loss: 0.0591 - val_accuracy: 0.9286 - val_loss: 0.2850\n",
      "Epoch 33/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 408ms/step - accuracy: 1.0000 - loss: 0.0564 - val_accuracy: 0.9286 - val_loss: 0.2834\n",
      "Epoch 34/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 409ms/step - accuracy: 1.0000 - loss: 0.0538 - val_accuracy: 0.9286 - val_loss: 0.2819\n",
      "Epoch 35/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 409ms/step - accuracy: 1.0000 - loss: 0.0514 - val_accuracy: 0.9286 - val_loss: 0.2806\n",
      "Epoch 36/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 409ms/step - accuracy: 1.0000 - loss: 0.0491 - val_accuracy: 0.9286 - val_loss: 0.2792\n",
      "Epoch 37/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 407ms/step - accuracy: 1.0000 - loss: 0.0470 - val_accuracy: 0.9286 - val_loss: 0.2779\n",
      "Epoch 38/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 407ms/step - accuracy: 1.0000 - loss: 0.0450 - val_accuracy: 0.9286 - val_loss: 0.2768\n",
      "Epoch 39/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 411ms/step - accuracy: 1.0000 - loss: 0.0431 - val_accuracy: 0.9286 - val_loss: 0.2757\n",
      "Epoch 40/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 410ms/step - accuracy: 1.0000 - loss: 0.0413 - val_accuracy: 0.9286 - val_loss: 0.2748\n",
      "Epoch 41/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 406ms/step - accuracy: 1.0000 - loss: 0.0397 - val_accuracy: 0.9286 - val_loss: 0.2740\n",
      "Epoch 42/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 407ms/step - accuracy: 1.0000 - loss: 0.0381 - val_accuracy: 0.9286 - val_loss: 0.2732\n",
      "Epoch 43/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 410ms/step - accuracy: 1.0000 - loss: 0.0366 - val_accuracy: 0.9286 - val_loss: 0.2724\n",
      "Epoch 44/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 408ms/step - accuracy: 1.0000 - loss: 0.0352 - val_accuracy: 0.9286 - val_loss: 0.2716\n",
      "Epoch 45/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 412ms/step - accuracy: 1.0000 - loss: 0.0339 - val_accuracy: 0.9286 - val_loss: 0.2707\n",
      "Epoch 46/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 406ms/step - accuracy: 1.0000 - loss: 0.0326 - val_accuracy: 0.9286 - val_loss: 0.2699\n",
      "Epoch 47/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 409ms/step - accuracy: 1.0000 - loss: 0.0314 - val_accuracy: 0.9286 - val_loss: 0.2692\n",
      "Epoch 48/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 408ms/step - accuracy: 1.0000 - loss: 0.0303 - val_accuracy: 0.9286 - val_loss: 0.2685\n",
      "Epoch 49/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 408ms/step - accuracy: 1.0000 - loss: 0.0292 - val_accuracy: 0.9286 - val_loss: 0.2678\n",
      "Epoch 50/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 408ms/step - accuracy: 1.0000 - loss: 0.0282 - val_accuracy: 0.9286 - val_loss: 0.2672\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "\n",
      "Evaluating text model on test set...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step - accuracy: 1.0000 - loss: 0.0671\n",
      "Text Model Validation Loss: 0.0671\n",
      "Text Model Validation Accuracy: 1.0000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 922ms/step\n",
      "\n",
      "Classification Report (Text Model):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         8\n",
      "           1       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n",
      "\n",
      "Confusion Matrix (Text Model):\n",
      "[[8 0]\n",
      " [0 7]]\n",
      "\n",
      "Additional Metrics for Test Results:\n",
      "Sensitivity (Recall): 1.0000\n",
      "Specificity: 1.0000\n",
      "AUC-ROC: 1.0000\n",
      "F1 Score: 1.0000\n",
      "\n",
      "Text single-view model training and evaluation complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-21 18:45:48.652316: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Input\n",
    "from transformers import AutoTokenizer, TFAutoModel\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, f1_score\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# --- Configuration ---\n",
    "# Path to CSV file\n",
    "CSV_FILE_PATH = 'dyslexia_data_with_text_duplicates_removed.csv'  \n",
    "\n",
    "# Batch size for training\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# Number of epochs for training the classifier head\n",
    "EPOCHS = 50\n",
    "\n",
    "# Learning rate for the classifier head\n",
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "# Seed used for splitting datasets\n",
    "seed = 24\n",
    "\n",
    "# --- Load and Prepare Data ---\n",
    "print(\"Loading data from CSV...\")\n",
    "try:\n",
    "    df = pd.read_csv(CSV_FILE_PATH)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: CSV file not found at {CSV_FILE_PATH}. Please check the path.\")\n",
    "    exit()\n",
    "\n",
    "# Check CSV has 'text' and 'presence_of_dyslexia' columns\n",
    "if 'text' not in df.columns or 'presence_of_dyslexia' not in df.columns:\n",
    "    print(\"Error: CSV must contain 'text' and 'presence_of_dyslexia' columns for text-only model.\")\n",
    "    exit()\n",
    "\n",
    "# Ensure 'text' column is string type and handle potential NaN values\n",
    "df['text'] = df['text'].fillna('').astype(str) # Fill NaN with empty string, then convert to str\n",
    "\n",
    "# Convert labels to integer type\n",
    "df['presence_of_dyslexia'] = df['presence_of_dyslexia'].astype(int)\n",
    "\n",
    "print(f\"Total samples: {len(df)}\")\n",
    "\n",
    "# --- Text Tokenization (Pre-tokenizing all text) ---\n",
    "print(\"Loading BERT tokenizer and tokenizing all text...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\") # Using bert-base-cased as we care about case \n",
    "\n",
    "all_input_ids = []\n",
    "all_attention_masks = []\n",
    "\n",
    "for text_entry in df['text']:\n",
    "    encoded_input = tokenizer(\n",
    "        text_entry,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=128, # Consistent max length\n",
    "        return_tensors='np' # Return NumPy arrays directly\n",
    "    )\n",
    "    all_input_ids.append(encoded_input['input_ids'][0])\n",
    "    all_attention_masks.append(encoded_input['attention_mask'][0])\n",
    "\n",
    "all_input_ids = np.array(all_input_ids)\n",
    "all_attention_masks = np.array(all_attention_masks)\n",
    "print(f\"All text tokenized. Input IDs shape: {all_input_ids.shape}, Attention Masks shape: {all_attention_masks.shape}\")\n",
    "\n",
    "# --- Split Preprocessed Data ---\n",
    "# Split data into training and validation sets for text only (70% - 15% - 15%)\n",
    "X_input_ids_train, X_input_ids_val, \\\n",
    "X_attention_masks_train, X_attention_masks_val, \\\n",
    "y_train, y_val = train_test_split(\n",
    "    all_input_ids,\n",
    "    all_attention_masks,\n",
    "    df['presence_of_dyslexia'].values,\n",
    "    test_size=0.3,\n",
    "    random_state=seed,\n",
    "    stratify=df['presence_of_dyslexia'].values\n",
    ")\n",
    "\n",
    "# --- Split Validation Data into Validation and Test ---\n",
    "# Then split data into validation and test sets for text only\n",
    "X_input_ids_val, X_input_ids_test, \\\n",
    "X_attention_masks_val, X_attention_masks_test, \\\n",
    "y_val, y_test = train_test_split(\n",
    "    X_input_ids_val,\n",
    "    X_attention_masks_val,\n",
    "    y_val,\n",
    "    test_size=0.5,\n",
    "    random_state=seed,\n",
    "    stratify=y_val\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(y_train)}\")\n",
    "print(f\"Validation samples: {len(y_val)}\")\n",
    "\n",
    "# --- Create TensorFlow Datasets from NumPy arrays (for text only) ---\n",
    "def create_tf_text_dataset_from_np(input_ids, attention_masks, labels):\n",
    "    \"\"\"\n",
    "    Creates a TensorFlow Dataset from NumPy arrays for text data.\n",
    "    \"\"\"\n",
    "    ds = tf.data.Dataset.from_tensor_slices(\n",
    "        (\n",
    "            {'input_ids': input_ids, 'attention_mask': attention_masks},\n",
    "            labels\n",
    "        )\n",
    "    )\n",
    "    ds = ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "train_dataset_text = create_tf_text_dataset_from_np(X_input_ids_train, X_attention_masks_train, y_train)\n",
    "val_dataset_text = create_tf_text_dataset_from_np(X_input_ids_val, X_attention_masks_val, y_val)\n",
    "test_dataset_text = create_tf_text_dataset_from_np(X_input_ids_test, X_attention_masks_test, y_test)\n",
    "\n",
    "print(\"TensorFlow Datasets created from preprocessed NumPy arrays for text.\")\n",
    "\n",
    "# --- Custom Keras Layer for BERT Model (re-used from multi-view) ---\n",
    "class BertEmbeddingLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, model_name, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.bert_model = TFAutoModel.from_pretrained(model_name, from_pt=True) \n",
    "        self.bert_model.trainable = False # Keep BERT layers frozen for feature extraction\n",
    "\n",
    "    def call(self, inputs):\n",
    "        input_ids = inputs['input_ids']\n",
    "        attention_mask = inputs['attention_mask']\n",
    "        # The training=False argument to prevent issues with symbolic tensors\n",
    "        bert_output = self.bert_model(input_ids, attention_mask=attention_mask, training=False)\n",
    "        # The [CLS] token output is typically at index 0 of the last_hidden_state\n",
    "        return bert_output.last_hidden_state[:, 0, :]\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\"model_name\": \"bert-base-cased\"}) # Match the tokenizer\n",
    "        return config\n",
    "\n",
    "# --- Define the Single-View Text Model ---\n",
    "print(\"Building single-view text model architecture...\")\n",
    "\n",
    "# Text Branch (BERT) using the custom layer\n",
    "bert_input_ids = keras.Input(shape=(128,), dtype=tf.int32, name='input_ids')\n",
    "bert_attention_mask = keras.Input(shape=(128,), dtype=tf.int32, name='attention_mask')\n",
    "\n",
    "bert_embedding_extractor = BertEmbeddingLayer(\"bert-base-cased\", name=\"bert_feature_extractor\") # Match the tokenizer\n",
    "text_features = bert_embedding_extractor({'input_ids': bert_input_ids, 'attention_mask': bert_attention_mask})\n",
    "print(\"BERT model wrapped in custom layer and layers frozen.\")\n",
    "\n",
    "classifier_head = Dense(768, activation='relu')(text_features) # A dense layer before the final output which will learn\n",
    "# Other option for slightly more complicated Classifier Head (New layers to be trained)\n",
    "#classifier_head = layers.Dense(256, activation='relu')(text_features)\n",
    "#classifier_head = layers.Dropout(0.3)(classifier_head)\n",
    "#classifier_head = layers.Dense(128, activation='relu')(classifier_head)\n",
    "#classifier_head = layers.Dropout(0.3)(classifier_head)\n",
    "output_layer = layers.Dense(1, activation='sigmoid', name='output')(classifier_head)\n",
    "\n",
    "# Create the final single-view text model\n",
    "text_model = keras.Model(\n",
    "    inputs={'input_ids': bert_input_ids, 'attention_mask': bert_attention_mask},\n",
    "    outputs=output_layer\n",
    ")\n",
    "\n",
    "# --- Compile and Train the Text Model ---\n",
    "print(\"Compiling text model...\")\n",
    "text_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "    loss=keras.losses.BinaryCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "text_model.summary()\n",
    "\n",
    "# Define the EarlyStopping callback\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Training text model...\")\n",
    "history_text = text_model.fit(\n",
    "    train_dataset_text,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_dataset_text,\n",
    "    callbacks=[early_stopping_callback]\n",
    ")\n",
    "\n",
    "# --- Evaluation for Text Model ---\n",
    "print(\"\\nEvaluating text model on test set...\")\n",
    "test_loss_text, test_accuracy_text = text_model.evaluate(test_dataset_text)\n",
    "print(f\"Text Model Validation Loss: {test_loss_text:.4f}\")\n",
    "print(f\"Text Model Validation Accuracy: {test_accuracy_text:.4f}\")\n",
    "\n",
    "# Generate predictions and classification report for text model\n",
    "all_preds_text = []\n",
    "all_labels_text = []\n",
    "# Create a dataset for prediction from test data for text\n",
    "predict_dataset_text = tf.data.Dataset.from_tensor_slices(\n",
    "    (\n",
    "        {'input_ids': X_input_ids_test, 'attention_mask': X_attention_masks_test},\n",
    "        y_test\n",
    "    )\n",
    ").batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "for inputs, labels in predict_dataset_text:\n",
    "    predictions = text_model.predict(inputs)\n",
    "    all_preds_text.extend(predictions.flatten().tolist())\n",
    "    all_labels_text.extend(labels.numpy().flatten().tolist())\n",
    "\n",
    "# Convert probabilities to binary predictions (0 or 1)\n",
    "binary_preds_text = np.array(all_preds_text) > 0.5\n",
    "\n",
    "print(\"\\nClassification Report (Text Model):\")\n",
    "print(classification_report(all_labels_text, binary_preds_text))\n",
    "\n",
    "print(\"\\nConfusion Matrix (Text Model):\")\n",
    "cm = confusion_matrix(all_labels_text, binary_preds_text)\n",
    "print(cm)\n",
    "\n",
    "# --- Calculate and Print Additional Metrics for Test Results ---\n",
    "print(\"\\nAdditional Metrics for Test Results:\")\n",
    "\n",
    "# Extract values from the confusion matrix\n",
    "# cm = [[TN, FP], [FN, TP]]\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "# Sensitivity (Recall)\n",
    "sensitivity = tp / (tp + fn)\n",
    "print(f\"Sensitivity (Recall): {sensitivity:.4f}\")\n",
    "\n",
    "# Specificity\n",
    "specificity = tn / (tn + fp)\n",
    "print(f\"Specificity: {specificity:.4f}\")\n",
    "\n",
    "# AUC-ROC\n",
    "# roc_auc_score requires probabilities, not binary predictions for `y_score`\n",
    "# all_preds_test contains the raw probabilities (0-1)\n",
    "auc_roc = roc_auc_score(all_labels_text, all_preds_text)\n",
    "print(f\"AUC-ROC: {auc_roc:.4f}\")\n",
    "\n",
    "# F1 Score\n",
    "f1 = f1_score(all_labels_text, binary_preds_text)\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "print(\"\\nText single-view model training and evaluation complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imperial_3_12_linux",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
